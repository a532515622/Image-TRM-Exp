2024-01-22 11:56:35,918 - 
use_gpu: 	True	
gpu: 	0	
res_dir: 	./results	
ex_name: 	trm1-22	
seed: 	1	
sample_size: 	16	
batch_size: 	64	
train_file_path: 	./data/all_data.csv	
val_file_path: 	./data/val_data.csv	
num_workers: 	6	
input_dim: 	49	
d_model: 	512	
nhead: 	8	
num_encoder_layers: 	6	
num_decoder_layers: 	6	
dim_feedforward: 	2048	
epochs: 	50	
log_step: 	100	
lr: 	0.001	
2024-01-22 11:56:58,076 - Epoch: 0, train loss: 9.2621
2024-01-22 11:56:58,785 - Epoch: 1, train loss: 0.1926
2024-01-22 11:56:59,497 - Epoch: 2, train loss: 0.0921
2024-01-22 11:57:00,211 - Epoch: 3, train loss: 0.0593
2024-01-22 11:57:00,916 - Epoch: 4, train loss: 0.0542
2024-01-22 11:57:01,615 - Epoch: 5, train loss: 0.0617
2024-01-22 11:57:02,317 - Epoch: 6, train loss: 0.0618
2024-01-22 11:57:03,015 - Epoch: 7, train loss: 0.0641
2024-01-22 11:57:03,713 - Epoch: 8, train loss: 0.0613
2024-01-22 11:57:04,410 - Epoch: 9, train loss: 0.0625
2024-01-22 11:57:05,106 - Epoch: 10, train loss: 0.0694
2024-01-22 11:57:05,798 - Epoch: 11, train loss: 0.0708
2024-01-22 11:57:06,496 - Epoch: 12, train loss: 0.0727
2024-01-22 11:57:07,194 - Epoch: 13, train loss: 0.0736
2024-01-22 11:57:07,888 - Epoch: 14, train loss: 0.0728
2024-01-22 11:57:08,579 - Epoch: 15, train loss: 0.0728
2024-01-22 11:57:09,277 - Epoch: 16, train loss: 0.0693
2024-01-22 11:57:09,971 - Epoch: 17, train loss: 0.0706
2024-01-22 11:57:10,670 - Epoch: 18, train loss: 0.0724
2024-01-22 11:57:11,367 - Epoch: 19, train loss: 0.0741
2024-01-22 11:57:12,097 - Epoch: 20, train loss: 0.0725
2024-01-22 11:57:12,795 - Epoch: 21, train loss: 0.0744
2024-01-22 11:57:13,490 - Epoch: 22, train loss: 0.0738
2024-01-22 11:57:14,181 - Epoch: 23, train loss: 0.0669
2024-01-22 11:57:14,900 - Epoch: 24, train loss: 0.0696
2024-01-22 11:57:15,600 - Epoch: 25, train loss: 0.0700
2024-01-22 11:57:16,299 - Epoch: 26, train loss: 0.0696
2024-01-22 11:57:17,038 - Epoch: 27, train loss: 0.0676
2024-01-22 11:57:17,750 - Epoch: 28, train loss: 0.0668
2024-01-22 11:57:18,444 - Epoch: 29, train loss: 0.0658
2024-01-22 11:57:19,164 - Epoch: 30, train loss: 0.0703
2024-01-22 11:57:19,894 - Epoch: 31, train loss: 0.0674
2024-01-22 11:57:20,631 - Epoch: 32, train loss: 0.0659
2024-01-22 11:57:21,849 - Epoch: 33, train loss: 0.0660
2024-01-22 11:57:22,558 - Epoch: 34, train loss: 0.0660
2024-01-22 11:57:23,259 - Epoch: 35, train loss: 0.0656
2024-01-22 11:57:23,958 - Epoch: 36, train loss: 0.0634
2024-01-22 11:57:24,657 - Epoch: 37, train loss: 0.0605
2024-01-22 11:57:25,353 - Epoch: 38, train loss: 0.0629
2024-01-22 11:57:26,049 - Epoch: 39, train loss: 0.0627
2024-01-22 11:57:26,746 - Epoch: 40, train loss: 0.0617
2024-01-22 11:57:27,467 - Epoch: 41, train loss: 0.0609
2024-01-22 11:57:28,170 - Epoch: 42, train loss: 0.0609
2024-01-22 11:57:28,907 - Epoch: 43, train loss: 0.0625
2024-01-22 11:57:29,671 - Epoch: 44, train loss: 0.0597
2024-01-22 11:57:30,379 - Epoch: 45, train loss: 0.0610
2024-01-22 11:57:31,112 - Epoch: 46, train loss: 0.0613
2024-01-22 11:57:31,877 - Epoch: 47, train loss: 0.0603
2024-01-22 11:57:32,641 - Epoch: 48, train loss: 0.0612
2024-01-22 11:57:33,450 - Epoch: 49, train loss: 0.0603
2024-01-22 15:00:03,771 - 
use_gpu: 	True	
gpu: 	0	
res_dir: 	./results	
ex_name: 	trm1-22	
seed: 	1	
sample_size: 	32	
batch_size: 	64	
train_file_path: 	./data/all_data.csv	
val_file_path: 	./data/val_data.csv	
num_workers: 	6	
input_dim: 	97	
d_model: 	512	
nhead: 	8	
num_encoder_layers: 	6	
num_decoder_layers: 	6	
dim_feedforward: 	2048	
epochs: 	100	
log_step: 	100	
lr: 	0.001	
2024-01-22 15:00:24,612 - Epoch: 0, train loss: 10.6152
2024-01-22 15:00:25,600 - Epoch: 1, train loss: 0.1966
2024-01-22 15:00:26,600 - Epoch: 2, train loss: 0.1235
2024-01-22 15:00:27,589 - Epoch: 3, train loss: 0.0734
2024-01-22 15:00:28,580 - Epoch: 4, train loss: 0.0552
2024-01-22 15:00:29,564 - Epoch: 5, train loss: 0.0536
2024-01-22 15:00:30,544 - Epoch: 6, train loss: 0.0646
2024-01-22 15:00:31,526 - Epoch: 7, train loss: 0.0673
2024-01-22 15:00:32,509 - Epoch: 8, train loss: 0.0724
2024-01-22 15:00:33,494 - Epoch: 9, train loss: 0.0725
2024-01-22 15:00:34,477 - Epoch: 10, train loss: 0.0660
2024-01-22 15:00:35,462 - Epoch: 11, train loss: 0.0697
2024-01-22 15:00:36,449 - Epoch: 12, train loss: 0.0685
2024-01-22 15:00:37,436 - Epoch: 13, train loss: 0.0739
2024-01-22 15:00:38,421 - Epoch: 14, train loss: 0.0728
2024-01-22 15:00:39,404 - Epoch: 15, train loss: 0.0728
2024-01-22 15:00:40,386 - Epoch: 16, train loss: 0.0749
2024-01-22 15:00:41,372 - Epoch: 17, train loss: 0.0725
2024-01-22 15:00:42,358 - Epoch: 18, train loss: 0.0737
2024-01-22 15:00:43,341 - Epoch: 19, train loss: 0.0765
2024-01-22 15:00:44,326 - Epoch: 20, train loss: 0.0802
2024-01-22 15:00:45,310 - Epoch: 21, train loss: 0.0780
2024-01-22 15:00:46,297 - Epoch: 22, train loss: 0.0796
2024-01-22 15:00:47,285 - Epoch: 23, train loss: 0.0799
2024-01-22 15:00:48,275 - Epoch: 24, train loss: 0.0789
2024-01-22 15:00:49,260 - Epoch: 25, train loss: 0.0764
2024-01-22 15:00:50,247 - Epoch: 26, train loss: 0.0726
2024-01-22 15:00:51,235 - Epoch: 27, train loss: 0.0712
2024-01-22 15:00:52,222 - Epoch: 28, train loss: 0.0696
2024-01-22 15:00:53,210 - Epoch: 29, train loss: 0.0729
2024-01-22 15:00:54,196 - Epoch: 30, train loss: 0.0730
2024-01-22 15:00:55,177 - Epoch: 31, train loss: 0.0737
2024-01-22 15:00:56,162 - Epoch: 32, train loss: 0.0698
2024-01-22 15:00:57,151 - Epoch: 33, train loss: 0.0692
2024-01-22 15:00:58,160 - Epoch: 34, train loss: 0.0714
2024-01-22 15:00:59,193 - Epoch: 35, train loss: 0.0681
2024-01-22 15:01:00,180 - Epoch: 36, train loss: 0.0662
2024-01-22 15:01:01,184 - Epoch: 37, train loss: 0.0679
2024-01-22 15:01:02,182 - Epoch: 38, train loss: 0.0662
2024-01-22 15:01:03,265 - Epoch: 39, train loss: 0.0672
2024-01-22 15:01:04,275 - Epoch: 40, train loss: 0.0636
2024-01-22 15:01:05,266 - Epoch: 41, train loss: 0.0668
2024-01-22 15:01:06,249 - Epoch: 42, train loss: 0.0658
2024-01-22 15:01:07,234 - Epoch: 43, train loss: 0.0658
2024-01-22 15:01:08,217 - Epoch: 44, train loss: 0.0665
2024-01-22 15:01:09,200 - Epoch: 45, train loss: 0.0641
2024-01-22 15:01:10,184 - Epoch: 46, train loss: 0.0658
2024-01-22 15:01:11,200 - Epoch: 47, train loss: 0.0627
2024-01-22 15:01:12,310 - Epoch: 48, train loss: 0.0632
2024-01-22 15:01:13,336 - Epoch: 49, train loss: 0.0629
2024-01-22 15:01:14,319 - Epoch: 50, train loss: 0.0631
2024-01-22 15:01:15,322 - Epoch: 51, train loss: 0.0635
2024-01-22 15:01:16,322 - Epoch: 52, train loss: 0.0627
2024-01-22 15:01:17,310 - Epoch: 53, train loss: 0.0617
2024-01-22 15:01:18,300 - Epoch: 54, train loss: 0.0623
2024-01-22 15:01:19,321 - Epoch: 55, train loss: 0.0617
2024-01-22 15:01:20,419 - Epoch: 56, train loss: 0.0627
2024-01-22 15:01:21,404 - Epoch: 57, train loss: 0.0621
2024-01-22 15:01:22,401 - Epoch: 58, train loss: 0.0616
2024-01-22 15:01:23,389 - Epoch: 59, train loss: 0.0600
2024-01-22 15:01:24,375 - Epoch: 60, train loss: 0.0587
2024-01-22 15:01:25,362 - Epoch: 61, train loss: 0.0570
2024-01-22 15:01:26,351 - Epoch: 62, train loss: 0.0589
2024-01-22 15:01:27,342 - Epoch: 63, train loss: 0.0600
2024-01-22 15:01:28,330 - Epoch: 64, train loss: 0.0586
2024-01-22 15:01:29,316 - Epoch: 65, train loss: 0.0588
2024-01-22 15:01:30,303 - Epoch: 66, train loss: 0.0590
2024-01-22 15:01:31,291 - Epoch: 67, train loss: 0.0550
2024-01-22 15:01:32,285 - Epoch: 68, train loss: 0.0557
2024-01-22 15:01:33,275 - Epoch: 69, train loss: 0.0563
2024-01-22 15:01:34,263 - Epoch: 70, train loss: 0.0573
2024-01-22 15:01:35,252 - Epoch: 71, train loss: 0.0567
2024-01-22 15:01:36,241 - Epoch: 72, train loss: 0.0558
2024-01-22 15:01:37,232 - Epoch: 73, train loss: 0.0574
2024-01-22 15:01:38,218 - Epoch: 74, train loss: 0.0540
2024-01-22 15:01:39,204 - Epoch: 75, train loss: 0.0546
2024-01-22 15:01:40,192 - Epoch: 76, train loss: 0.0559
2024-01-22 15:01:41,183 - Epoch: 77, train loss: 0.0547
2024-01-22 15:01:42,175 - Epoch: 78, train loss: 0.0543
2024-01-22 15:01:43,163 - Epoch: 79, train loss: 0.0539
2024-01-22 15:01:44,153 - Epoch: 80, train loss: 0.0543
2024-01-22 15:01:45,144 - Epoch: 81, train loss: 0.0540
2024-01-22 15:01:46,137 - Epoch: 82, train loss: 0.0538
2024-01-22 15:01:47,141 - Epoch: 83, train loss: 0.0550
2024-01-22 15:01:48,136 - Epoch: 84, train loss: 0.0549
2024-01-22 15:01:49,127 - Epoch: 85, train loss: 0.0526
2024-01-22 15:01:50,118 - Epoch: 86, train loss: 0.0540
2024-01-22 15:01:51,107 - Epoch: 87, train loss: 0.0540
2024-01-22 15:01:52,101 - Epoch: 88, train loss: 0.0535
2024-01-22 15:01:53,090 - Epoch: 89, train loss: 0.0531
2024-01-22 15:01:54,080 - Epoch: 90, train loss: 0.0551
2024-01-22 15:01:55,070 - Epoch: 91, train loss: 0.0520
2024-01-22 15:01:56,062 - Epoch: 92, train loss: 0.0520
2024-01-22 15:01:57,051 - Epoch: 93, train loss: 0.0520
2024-01-22 15:01:58,085 - Epoch: 94, train loss: 0.0534
2024-01-22 15:01:59,101 - Epoch: 95, train loss: 0.0541
2024-01-22 15:02:00,092 - Epoch: 96, train loss: 0.0533
2024-01-22 15:02:01,083 - Epoch: 97, train loss: 0.0527
2024-01-22 15:02:02,077 - Epoch: 98, train loss: 0.0525
2024-01-22 15:02:03,076 - Epoch: 99, train loss: 0.0513
